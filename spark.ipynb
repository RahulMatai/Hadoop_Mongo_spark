{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Joycu8i8ZnqY"
      },
      "source": [
        "## 5. PySpark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8eAmsY40ZmWw"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrOPixEoZ3Tr",
        "outputId": "f35bc988-0aa9-4491-dfbb-40c36b20967a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-12-11 21:21:10--  https://dlcdn.apache.org/spark/spark-3.3.1/spark-3.3.1-bin-hadoop3.tgz\n",
            "Resolving dlcdn.apache.org (dlcdn.apache.org)... 151.101.2.132, 2a04:4e42::644\n",
            "Connecting to dlcdn.apache.org (dlcdn.apache.org)|151.101.2.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 299350810 (285M) [application/x-gzip]\n",
            "Saving to: ‘spark-3.3.1-bin-hadoop3.tgz’\n",
            "\n",
            "spark-3.3.1-bin-had 100%[===================>] 285.48M   206MB/s    in 1.4s    \n",
            "\n",
            "2022-12-11 21:21:11 (206 MB/s) - ‘spark-3.3.1-bin-hadoop3.tgz’ saved [299350810/299350810]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://dlcdn.apache.org/spark/spark-3.3.1/spark-3.3.1-bin-hadoop3.tgz\n",
        "!tar xf spark-3.3.1-bin-hadoop3.tgz\n",
        "!rm spark-3.3.1-bin-hadoop3.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "J8uydZGOaCJy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.3.1-bin-hadoop3\"\n",
        "\n",
        "!pip install -q findspark\n",
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TvmEgLEkaE1w"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True) #  This will format our output tables a bit nicer when not using the show() method\n",
        "spark\n",
        "\n",
        "import multiprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0LFx0fo1aNUS"
      },
      "outputs": [],
      "source": [
        "sc = spark.sparkContext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62dX9w1OaQ0U",
        "outputId": "d345f55b-f868-44c1-d716-e3e8e673ae48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-12-11 21:21:41--  https://csserver.ucd.ie/~thomas/tweets.tsv\n",
            "Resolving csserver.ucd.ie (csserver.ucd.ie)... 193.1.133.60\n",
            "Connecting to csserver.ucd.ie (csserver.ucd.ie)|193.1.133.60|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 22470255 (21M) [text/tab-separated-values]\n",
            "Saving to: ‘tweets.tsv’\n",
            "\n",
            "tweets.tsv          100%[===================>]  21.43M  15.0MB/s    in 1.4s    \n",
            "\n",
            "2022-12-11 21:21:43 (15.0 MB/s) - ‘tweets.tsv’ saved [22470255/22470255]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://csserver.ucd.ie/~thomas/tweets.tsv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNhVi-lqaWTc",
        "outputId": "d8e15aeb-927a-46e8-91e7-c4be7b0db701"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+-------------------+-------------------+---------------+--------------------+\n",
            "|wordle_id|           tweet_id|         tweet_date| tweet_username|          tweet_text|\n",
            "+---------+-------------------+-------------------+---------------+--------------------+\n",
            "|      210|1482553374591660037|2022-01-16 03:20:43|       bpszebes|Wordle 210 4/6  ⬛...|\n",
            "|      210|1482553387937898499|2022-01-16 03:20:46|     cruisecoup|Wordle 210 4/6  ⬜...|\n",
            "|      210|1482553422276698113|2022-01-16 03:20:55|     DestroVega|Wordle 210 4/6  ⬜...|\n",
            "|      210|1482553436910628866|2022-01-16 03:20:58|    brenmardash|Wordle 210 3/6  ⬜...|\n",
            "|      210|1482553445726908420|2022-01-16 03:21:00|    KatieHowse2|Wordle 210 3/6  ⬛...|\n",
            "|      210|1482553448025395202|2022-01-16 03:21:01|        iconoco|Wordle 210 4/6  ⬛...|\n",
            "|      210|1482553451439603720|2022-01-16 03:21:01|   ParickHarmon|Wordle 210 3/6  ?...|\n",
            "|      210|1482553460251709443|2022-01-16 03:21:04|     Revnan2001|Wordle 210 4/6  ⬜...|\n",
            "|      210|1482553474243981312|2022-01-16 03:21:07|       sarajmun|Wordle 210 2/6  ?...|\n",
            "|      210|1482553491050700800|2022-01-16 03:21:11|     CraigBatts|Wordle 210 2/6  ⬜...|\n",
            "|      210|1482553587750215682|2022-01-16 03:21:34|DavidBowman2021|Wordle 210 4/6  ⬜...|\n",
            "|      210|1482553597443207168|2022-01-16 03:21:36|   Ilovelucy907|Wordle 210 4/6  ⬛...|\n",
            "|      210|1482553600551579648|2022-01-16 03:21:37| Wasatchwarrior|Wordle 210 3/6  ⬜...|\n",
            "|      210|1482553601323159553|2022-01-16 03:21:37|       maggie77|Wordle 210 3/6  ?...|\n",
            "|      210|1482553626241372162|2022-01-16 03:21:43|   marisasimone|Wordle 210 4/6  ⬛...|\n",
            "|      210|1482553633803845634|2022-01-16 03:21:45|    Akilragavan|Wordle 210 4/6  ⬛...|\n",
            "|      210|1482553642649587716|2022-01-16 03:21:47|    ShroomShoom|Wordle 210 4/6  ⬛...|\n",
            "|      210|1482553649486344194|2022-01-16 03:21:49|        exec101|Wordle 210 3/6  ⬜...|\n",
            "|      210|1482553676849893379|2022-01-16 03:21:55|    niklas_ross|Wordle 210 3/6  ⬛...|\n",
            "|      210|1482553684294873090|2022-01-16 03:21:57|         iBrews|Wordle 210 4/6  ⬛...|\n",
            "|      210|1482553685054005251|2022-01-16 03:21:57|    anna_aileen|Wordle 210 4/6  ⬜...|\n",
            "|      210|1482553690775257094|2022-01-16 03:21:59|  VilliamToledo|Wordle 210 6/6  ⬜...|\n",
            "|      210|1482553709674459139|2022-01-16 03:22:03|  indoor__voice|Wordle 210 3/6  ⬛...|\n",
            "|      210|1482553729912033283|2022-01-16 03:22:08|      matty_som|Wordle 210 4/6  ⬛...|\n",
            "|      210|1482553747939237894|2022-01-16 03:22:12|        ryanf07|Wordle 210 3/6  ⬛...|\n",
            "|      210|1482553769669709825|2022-01-16 03:22:17|      ahj_in_sf|Wordle 210 2/6  ?...|\n",
            "|      210|1482553794525208578|2022-01-16 03:22:23|   superrrmodel|Wordle 210 4/6  ⬜...|\n",
            "|      210|1482553807586217990|2022-01-16 03:22:26|leahmachtsachen|Wordle 210 3/6  ⬛...|\n",
            "|      210|1482553816545468417|2022-01-16 03:22:29|   rodertouille|Wordle 210 3/6  ⬛...|\n",
            "|      210|1482553834648084484|2022-01-16 03:22:33|ameliaaaaaaaphd|Wordle 210 4/6  ?...|\n",
            "+---------+-------------------+-------------------+---------------+--------------------+\n",
            "only showing top 30 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df = spark.read.options(delimiter=\"\\t\", header=True,inferSchema=True).csv(\"tweets.tsv\")\n",
        "df.select(\"*\").show(30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Jb9Tm8ze7jod"
      },
      "outputs": [],
      "source": [
        "rdd = df.rdd.map(list)\n",
        "rddCollect = rdd.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jef5ZLtvagDC",
        "outputId": "21108ee1-2211-48ec-a15b-9d41358d2474"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+-----+\n",
            "|wordle_id|count|\n",
            "+---------+-----+\n",
            "|      223|15776|\n",
            "+---------+-----+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Most tweeted Wordle Puzzle \n",
        "df.groupBy(\"wordle_id\").count().orderBy(\"count\", ascending=False).show(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4k423ytcABj",
        "outputId": "cbc17f62-865e-40b5-e90e-7e31cfa2b83c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(4096, 617, 136964)\n",
            "count of (wordle) :  136964\n",
            "count of (the) :  4096\n",
            "count of (play) : 617\n"
          ]
        }
      ],
      "source": [
        "#Count of wordle, play, the  in descending order\n",
        "list_of_count = df.filter(df.tweet_text.rlike(\"the\")).count() ,df.filter(df.tweet_text.rlike(\"play\")).count(),df.filter(df.tweet_text.rlike(\"Wordle\")).count()\n",
        "print (list_of_count)\n",
        "sorted_list = list(list_of_count)\n",
        "sorted_list.sort(reverse=True)\n",
        "print('count of (wordle) : ',sorted_list[0])\n",
        "print('count of (the) : ',sorted_list[1])\n",
        "print('count of (play) :',sorted_list[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "bdnfy4v_Hdll",
        "outputId": "59d32ff5-3ecb-4844-c816-387c82061a66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 38 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 63.4 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.1-py2.py3-none-any.whl size=281845512 sha256=37b8227d2b4722d823cefcb95630b15c5a67510b56a8ddd21e62ef54b94abee7\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/dc/11/ec201cd671da62fa9c5cc77078235e40722170ceba231d7598\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.1\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "py4j",
                  "pyspark"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install pyspark\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saeF61HDalaY",
        "outputId": "9284f154-de3a-4e2b-8ef2-e1c396e7375d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------------+--------+\n",
            "|most_tweeted_day|count(1)|\n",
            "+----------------+--------+\n",
            "|             Fri|   28737|\n",
            "+----------------+--------+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.createOrReplaceTempView(\"most_games_tweets\")\n",
        "output = spark.sql(\"\"\"SELECT DATE_FORMAT(tweet_date,'E') as most_tweeted_day, count(1) \n",
        "            FROM most_games_tweets GROUP BY most_tweeted_day ORDER BY count(1) DESC\"\"\")\n",
        "output.show(1)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.9 (tags/v3.7.9:13c94747c7, Aug 17 2020, 18:58:18) [MSC v.1900 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "2d4f0a46cd29155c05dc1db2a5273a091d51a5243ea4bfe3fb06387f3918af53"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
